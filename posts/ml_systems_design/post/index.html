<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Designing Machine Learning Systems: A Summary | Minh T. Nguyen</title>
<meta name="keywords" content="paper-reading">
<meta name="description" content="Chip Huyen&#39;s guide to design machine learning systems - a brief overview.">
<meta name="author" content="Minh T. Nguyen">
<link rel="canonical" href="https://mnguyen0226.github.io/posts/ml_systems_design/post/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css" integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe&#43;FVUFzPh7U=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<link rel="apple-touch-icon" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<link rel="mask-icon" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Designing Machine Learning Systems: A Summary" />
<meta property="og:description" content="Chip Huyen&#39;s guide to design machine learning systems - a brief overview." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mnguyen0226.github.io/posts/ml_systems_design/post/" /><meta property="og:image" content="https://mnguyen0226.github.io/papermod-cover.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-08T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-05-08T00:00:00+00:00" />
<meta property="og:see_also" content="https://mnguyen0226.github.io/posts/multitask_learning/post/" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://mnguyen0226.github.io/papermod-cover.png"/>

<meta name="twitter:title" content="Designing Machine Learning Systems: A Summary"/>
<meta name="twitter:description" content="Chip Huyen&#39;s guide to design machine learning systems - a brief overview."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://mnguyen0226.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Designing Machine Learning Systems: A Summary",
      "item": "https://mnguyen0226.github.io/posts/ml_systems_design/post/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Designing Machine Learning Systems: A Summary",
  "name": "Designing Machine Learning Systems: A Summary",
  "description": "Chip Huyen's guide to design machine learning systems - a brief overview.",
  "keywords": [
    "paper-reading"
  ],
  "articleBody": "Status: [Latest]\nChip Huyen, a Vietnamese writer, computer scientist, and co-founder of Claypot AI, has an impressive background as a lecturer at Stanford and as a machine learning engineer at NVIDIA, Snorkel AI, Netflix, and Primer. I have been an avid reader of Chip’s books since her best-selling works in Vietnam, which inspired me to pursue my study-abroad journey in the U.S. Her latest book, published in June 2022, offers invaluable insights and practical advice on building reliable machine learning systems. After reading it for the first time, I was captivated by the depth of knowledge shared, prompting me to revisit the book multiple times to fully absorb its ideas. In this blog post, I will share my reflections and takeaways from Chip Huyen’s book after the first-read, which has greatly influenced my understanding and approach to machine learning.\nFig. 1. Book cover. (Image source: O'Reilly). Overview of ML Systems In her book, Chip Huyen presents an overview of ML systems, defining eight main components that constitute such systems. The book adopts a “divide-and-conquer” approach, examining each component individually to facilitate a comprehensive understanding of the entire system.\nFig. 2. Machine learning system components. (Image inspired from: O'Reilly). Chip’s definition of machine learning revolves around learning complex patterns from existing data and using them to make predictions on unseen data. This definition aligns with the prevalent use of supervised learning, as most ML applications involve leveraging vast amounts of user data stored in SQL databases.\nSo why does company integrate ML in their product? Companies integrate ML into their products due to the low cost of wrong predictions, scalability advantages, and the ability of ML models to adapt to changing patterns. For example, by identifying potential customers, displaying targeted ads, and offering timely discounts, companies like Lyft can significantly increase profits by reducing costs and attracting more long-term users.\nSo what is the difference between traditional software vs. ML? There are notable differences between traditional software engineering (SWE) and ML systems. In SWE, the emphasis is on modular and separated components, whereas in ML systems, code and data intertwine, making it challenging to apply SWE principles such as S.O.L.I.D or the 12-factor app to these systems.\nFig. 3. SWE vs. ML. (Image inspired from: O'Reilly). Considerations Before applying ML algorithms to solve a problem, it is essential to frame the problem in a way that ML can address it effectively. This involves determining the appropriate task for ML, such as binary classification, multi-class classification, or regression.\nWhile ML metrics like accuracy or F1 score are important, most companies prioritize the ultimate goal of any project: increasing profit. This can be achieved by boosting sales, reducing costs, enhancing customer satisfaction, or increasing app engagement.\nFig. 4. Integration in SWE or ML need to be align with business. (Image source: MonkeyUser.com). Predicting ad click-through rates and fraud detection are popular ML use cases because they directly impact business metrics. Higher click-through rates translate into increased ad revenue, while detecting and preventing fraudulent transactions saves money.\nData \u0026 Feature Engineering Let’s look at how data can be handled in the data science perspective. For now, I will focus on sampling, labeling, and feature engineering techniques.\nData Sampling To create train/validate/test sets, there are various data sampling techniques available. Two common approaches include random sampling and stratified sampling.\nData Labeling When it comes to data labeling, there are several options to consider:\nHand-labeling: This approach can be expensive, time-consuming, and may raise concerns about data privacy. Third-party service: Companies like Scale AI offer data labeling services and have recently secured significant contracts, such as the $250 million data labeling contract from the Department of Defense. Benchmark datasets: Utilizing established benchmark datasets like ImageNet and BATADAL can provide pre-labeled data for specific tasks. Methodological changes: If feasible, it's possible to switch from traditional supervised learning with training from scratch to alternative approaches like transfer learning, self-supervised learning, or semi-supervised learning. These methods can reduce the reliance on extensive labeled data. Fig. 5. Finding a suitable dataset and processing it for specific task is crucial for intended application purposes. (Image source: MonkeyUser.com). Feature Engineering The significance of feature engineering cannot be overstated in the development of ML models. Even with state-of-the-art ML architectures, performance can suffer if an inadequate set of features is used. While (deep learning) models can extract features to some extent, providing well-engineered features that enable the model to better comprehend the data can greatly benefit your application. By inputting carefully selected and curated features, you enhance the model’s ability to effectively capture and utilize relevant information.\nML Algorithms \u0026 Evaluation Let’s see what is Chip’s tips in terms of suitable ML algorithm(s), training paradigm, and evaluation metrics.\nModel Selection Given the constraints of limited computation power and time, it is crucial to strategically choose ML models based on their advantages and disadvantages. This is where the knowledge gained from classes and academic papers becomes applicable. Benchmark datasets, such as ImageNet, SMAC, or VQA, can serve as valuable references for model selection. Additionally, factors like the number of parameters (model complexity) and interpretability can influence the choice of models. The availability of auto-selecting tools like AutoML from H2O.ai or AutoTrain from HuggingFace provides reasonable options as well.\nDistributed Training Paradigms Consideration of distributed training paradigms is important when dealing with large models or datasets. Let’s examine data parallelism and model parallelism.\nData parallelism involves splitting the data across multiple machines, training the model on each machine, and accumulating gradients.\nModel parallelism, on the other hand, involves training different components of the model on different machines. For instance, machine 0 handles the computation for the first two layers while machine 1 handles the next two layers. It’s important to note that “model parallelism” can be misleading because in some cases, parallel execution doesn’t occur across different parts of the model on different machines. Instead, each part is executed sequentially or consecutively.\nFig. 6. Data parallelism vs. model parallelism. (Image source: anyscale.com). Model Evaluation Deploying a model involves more than simply pickling the model and using it in a Python script. There are several important aspects to consider in the deployment process.\nModel Deployment Model deployment is not simply “pickle” the model and use it on a Python script, there are several aspects to be considered.\nBatch vs. Online Training Online prediction is when predictions are generated and returned as soon as requests for these predictions arrive. For example, you enter an English sentence into Google Translate and get back its French translation immediately. When doing online prediction, requests are sent to the prediction service via RESTful APIs, that means to send back the input data, call model prediction and return the prediction result\nBatch prediction is when predictions are generated periodically or whenever triggered. The predictions are stored somewhere, such as in SQL tables or an in-memory database, and retrieved as needed. For example, Netflix might generate movie recommendations for all of its users every four hours, and the precomputed recommendations are fetched and shown to users when they log on to Netflix. For example, every 4 hours, Netflix might generate movie recommendations for all of its users.\nModel Compression In scenarios where convolutional neural networks are used, model compression techniques can be applied. For example, replacing the convolutional layer with depth-wise separable convolutional layers can significantly reduce the number of parameters while maintaining performance. Similarly, classical ML algorithms like Decision Trees can be pruned to reduce model complexity.\nCloud vs. Hardware Model deployment options include cloud deployment to platforms like AWS or GCP and hardware deployment, often referred to as edge computing. Cloud deployment offers scalability but comes with associated costs ranging from $50K to $2M per year. On the other hand, hardware deployment enables models to operate in environments with limited or unreliable internet connectivity, such as rural areas or developing countries. Edge computing also reduces network latency concerns. However, privacy risks still exist, as attackers could potentially steal user data by physically accessing the devices. Major companies like Google, Apple, and Tesla are actively developing their own chips optimized for edge computing.\nFig. 7. Google's Pixel 6 Tensor Chip, Apple's M1 Chip, Tesla's D1 Chip. In support of the semiconductor industry, the CHIPS and Science Act was signed by President Biden on August 9, 2022, aiming to strengthen the US semiconductor supply chain and foster research and development of advanced technologies within the country.\nInfrastructure The right infrastructure setup can automate processes, saving engineering time, accelerating ML application development and delivery, reducing the risk of bugs, and enabling new use cases. Conversely, a poorly implemented infrastructure can be cumbersome and costly to replace.\nFig. 8. ML layers of tools to build reliable infrastructure. Storage: is where data is collected and stored. It can range from simple setups like hard disk drives (HDD) or solid-state drives (SSD) to more sophisticated solutions like centralized storage in platforms such as Amazon S3 or Snowflake. Data can be stored in a single location or distributed across multiple locations.\nResource Management: comprises tools to schedule and orchestrate your workloads to make the most out of your available compute resources. Popular examples in this category include Airflow, Kubeflow, and Metaflow, which help manage and allocate computing resources efficiently.\nML Platform: provides tools to aid the development of ML applications such as model stores, feature stores, and monitoring tools. Prominent examples of ML platforms include SageMaker and MLflow, which provide comprehensive capabilities for ML application development and management.\nDeployment: Major cloud providers like AWS (SageMaker), GCP (Vertex AI), Azure (Azure ML), and Alibaba (Machine Learning) offer robust deployment options for ML applications. These platforms provide infrastructure and services to streamline the deployment process and ensure scalability and reliability.\nDevelopment Environment: A variety of development environments are available to facilitate ML application development. Tools such as VS Code, PyCharm, Anaconda, Jupyter Notebook, Git, and Docker are commonly used by data scientists and developers to write and manage code, create reproducible environments, and collaborate efficiently.\nTeam Structures In many job descriptions, it is common to see Data Scientists taking ownership of the entire process, from data collection to productionization. However, Netflix has implemented an effective team structure for full-stack data scientists.\nNetflix’s model involves specialists who initially own specific parts of a project. These specialists create tools and automation to streamline their respective areas. Data scientists can then leverage these tools to take ownership of their projects from end to end. As tools are developed and integrated with each other, the entire workflow is cohesive and well-integrated.\nThis team structure at Netflix allows for a seamless collaboration where specialists contribute their expertise to build tools, and data scientists can utilize these tools to manage the complete life cycle of their projects.\nFig. 9. Netflix's full cycle data science development with specialists create reusable tools. (Image source: Netflix Technology Blog). Citation Cited as:\nNguyen, Minh. (May 2023). Designing Machine Learning Systems: A Summary. https://mnguyen0226.github.io/posts/ml_systems_design/post/. Or\n@article{nguyen2023mlsys, title = \"Designing Machine Learning Systems: A Summary.\", author = \"Nguyen, Minh\", journal = \"mnguyen0226.github.io\", year = \"2023\", month = \"May\", url = \"https://mnguyen0226.github.io/posts/ml_systems_design/post/\" } References [1] “Full cycle developers at Netflix,” Medium, https://netflixtechblog.com/full-cycle-developers-at-netflix-a08c31f83249 (accessed May 19, 2023).\n[2] “President Biden Signs Chips and science act into law,” White \u0026 Case LLP, https://www.whitecase.com/insight-alert/president-biden-signs-chips-and-science-act-law (accessed May 19, 2023).\n[3] “Cloud cost management and optimization by ANODOT,” Anodot, https://www.anodot.com/cloud-cost-management/ (accessed May 19, 2023).\n[4] F. Chollet, “Xception: Deep learning with depthwise separable convolutions,” arXiv.org, https://arxiv.org/abs/1610.02357 (accessed May 19, 2023).\n[5] C. Huyen, “Introduction to streaming for Data scientists,” Chip Huyen, https://huyenchip.com/2022/08/03/stream-processing-for-data-scientists.html#:~:text=Batch%20prediction%20means%20periodically%20generating,whenever%20they%20visit%20the%20website. (accessed May 19, 2023).\n[6] Y. Wu et al., “Google’s Neural Machine Translation System: Bridging the gap between human and machine translation,” arXiv.org, https://arxiv.org/abs/1609.08144 (accessed May 19, 2023).\n[7] “What is distributed training?,” Anyscale, https://www.anyscale.com/blog/what-is-distributed-training (accessed May 19, 2023).\n[8] VQA: Visual question answering | IEEE conference publication - IEEE xplore, https://ieeexplore.ieee.org/document/7410636 (accessed May 19, 2023).\n[9] B. Ellis et al., “SMACv2: An improved benchmark for cooperative multi-agent reinforcement learning,” arXiv.org, https://arxiv.org/abs/2212.07489 (accessed May 19, 2023).\n[10] Practical lessons from predicting clicks on ads at facebook, https://quinonero.net/Publications/predicting-clicks-facebook.pdf (accessed May 19, 2023).\n[11] “Scale AI selected by U.S. Department of Defense to accelerate government’s AI capabilities,” Business Wire, https://www.businesswire.com/news/home/20220131005304/en/Scale-AI-Selected-by-U.S.-Department-of-Defense-to-Accelerate-Government%E2%80%99s-AI-Capabilities (accessed May 19, 2023).\n[12] “Deep learning with python,” Manning Publications, https://www.manning.com/books/deep-learning-with-python (accessed May 19, 2023).\n[13] J. Henriksen, “Valuing lyft requires a deep look into unit economics,” Forbes, https://www.forbes.com/sites/jeffhenriksen/2019/05/17/valuing-lyft-requires-a-deep-look-into-unit-economics/?sh=17155c9a7add (accessed May 19, 2023).\n[14] L. Ceci and J. 7, “Mobile app user acquisition cost 2019,” Statista, https://www.statista.com/statistics/185736/mobile-app-average-user-acquisition-cost/ (accessed May 19, 2023).\n[15] C. Huyen, “Designing machine learning systems,” O’Reilly Online Learning, https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/ (accessed May 19, 2023).\nFig. 10. Morning hike at McAfee Knob, Roanoke, Virginia, U.S.A. ",
  "wordCount" : "2109",
  "inLanguage": "en",
  "datePublished": "2023-05-08T00:00:00Z",
  "dateModified": "2023-05-08T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Minh T. Nguyen"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://mnguyen0226.github.io/posts/ml_systems_design/post/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Minh T. Nguyen",
    "logo": {
      "@type": "ImageObject",
      "url": "https://mnguyen0226.github.io/favicon/android-chrome-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://mnguyen0226.github.io/" accesskey="h" title="Minh T. Nguyen (Alt + H)">Minh T. Nguyen</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://mnguyen0226.github.io/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://mnguyen0226.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://mnguyen0226.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      Designing Machine Learning Systems: A Summary
    </h1>
    <div class="post-description">
      Chip Huyen&#39;s guide to design machine learning systems - a brief overview.
    </div>
    <div class="post-meta"><span title='2023-05-08 00:00:00 +0000 UTC'>May 8, 2023</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Minh T. Nguyen

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#overview-of-ml-systems" aria-label="Overview of ML Systems">Overview of ML Systems</a></li>
                <li>
                    <a href="#considerations" aria-label="Considerations">Considerations</a></li>
                <li>
                    <a href="#data--feature-engineering" aria-label="Data &amp;amp; Feature Engineering">Data &amp; Feature Engineering</a><ul>
                        
                <li>
                    <a href="#data-sampling" aria-label="Data Sampling">Data Sampling</a></li>
                <li>
                    <a href="#data-labeling" aria-label="Data Labeling">Data Labeling</a></li>
                <li>
                    <a href="#feature-engineering" aria-label="Feature Engineering">Feature Engineering</a></li></ul>
                </li>
                <li>
                    <a href="#ml-algorithms--evaluation" aria-label="ML Algorithms &amp;amp; Evaluation">ML Algorithms &amp; Evaluation</a><ul>
                        
                <li>
                    <a href="#model-selection" aria-label="Model Selection">Model Selection</a></li>
                <li>
                    <a href="#distributed-training-paradigms" aria-label="Distributed Training Paradigms">Distributed Training Paradigms</a></li>
                <li>
                    <a href="#model-evaluation" aria-label="Model Evaluation">Model Evaluation</a></li></ul>
                </li>
                <li>
                    <a href="#model-deployment" aria-label="Model Deployment">Model Deployment</a><ul>
                        
                <li>
                    <a href="#batch-vs-online-training" aria-label="Batch vs. Online Training">Batch vs. Online Training</a></li>
                <li>
                    <a href="#model-compression" aria-label="Model Compression">Model Compression</a></li>
                <li>
                    <a href="#cloud-vs-hardware" aria-label="Cloud vs. Hardware">Cloud vs. Hardware</a></li></ul>
                </li>
                <li>
                    <a href="#infrastructure" aria-label="Infrastructure">Infrastructure</a></li>
                <li>
                    <a href="#team-structures" aria-label="Team Structures">Team Structures</a></li>
                <li>
                    <a href="#citation" aria-label="Citation">Citation</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p style="color: #286EE0"><strong>Status:</strong> [Latest]</p>
<p>Chip Huyen, a Vietnamese writer, computer scientist, and co-founder of Claypot AI, has an impressive background as a lecturer at Stanford and as a machine learning engineer at NVIDIA, Snorkel AI, Netflix, and Primer. I have been an avid reader of Chip&rsquo;s books since her best-selling works in Vietnam, which inspired me to pursue my study-abroad journey in the U.S. Her latest book, published in June 2022, offers invaluable insights and practical advice on building reliable machine learning systems. After reading it for the first time, I was captivated by the depth of knowledge shared, prompting me to revisit the book multiple times to fully absorb its ideas. In this blog post, I will share my reflections and takeaways from Chip Huyen&rsquo;s book after the <strong>first-read</strong>, which has greatly influenced my understanding and approach to machine learning.</p>
<center>
    <img style="width: 25%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/book.png" />
</center>
<figcaption class="img_footer">
    Fig. 1. Book cover.
    (Image source: 
    <a href="https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/" class="img_footer"> O'Reilly</a>).
</figcaption>
<h2 id="overview-of-ml-systems">Overview of ML Systems<a hidden class="anchor" aria-hidden="true" href="#overview-of-ml-systems">#</a></h2>
<p>In her book, Chip Huyen presents an overview of ML systems, defining eight main components that constitute such systems. The book adopts a &ldquo;divide-and-conquer&rdquo; approach, examining each component individually to facilitate a comprehensive understanding of the entire system.</p>
<center>
    <img style="width: 90%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/ml_system_diagram_.png" />
</center>
<figcaption class="img_footer">
    Fig. 2. Machine learning system components.
    (Image inspired from: 
    <a href="https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/" class="img_footer"> O'Reilly</a>).
</figcaption>
</br>
<p>Chip&rsquo;s definition of machine learning revolves around learning complex patterns from existing data and using them to make predictions on unseen data. This definition aligns with the prevalent use of supervised learning, as most ML applications involve leveraging vast amounts of user data stored in SQL databases.</p>
<p><strong>So why does company integrate ML in their product?</strong> Companies integrate ML into their products due to the low cost of wrong predictions, scalability advantages, and the ability of ML models to adapt to changing patterns. For example, by identifying potential customers, displaying targeted ads, and offering timely discounts, companies like Lyft can significantly increase profits by reducing costs and attracting more long-term users.</p>
<p><strong>So what is the difference between traditional software vs. ML?</strong> There are notable differences between traditional software engineering (SWE) and ML systems. In SWE, the emphasis is on modular and separated components, whereas in ML systems, code and data intertwine, making it challenging to apply SWE principles such as <a href="https://mnguyen0226.github.io/posts/solid_principles/post/">S.O.L.I.D</a> or the <a href="https://12factor.net/">12-factor app</a> to these systems.</p>
<center>
    <img style="width: 100%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/swe_vs_ml_.png" />
</center>
<figcaption class="img_footer">
    Fig. 3. SWE vs. ML.
    (Image inspired from: 
    <a href="https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/" class="img_footer"> O'Reilly</a>).
</figcaption>
<h2 id="considerations">Considerations<a hidden class="anchor" aria-hidden="true" href="#considerations">#</a></h2>
<p>Before applying ML algorithms to solve a problem, it is essential to frame the problem in a way that ML can address it effectively. This involves determining the appropriate task for ML, such as binary classification, multi-class classification, or regression.</p>
<p>While ML metrics like accuracy or F1 score are important, most companies prioritize the ultimate goal of any project: increasing profit. This can be achieved by boosting sales, reducing costs, enhancing customer satisfaction, or increasing app engagement.</p>
<center>
    <img style="width: 50%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/architecture_cartoon.png" />
</center>
<figcaption class="img_footer">
    Fig. 4. Integration in SWE or ML need to be align with business.</br>
    (Image source: 
    <a href="https://www.monkeyuser.com/2018/architecture/" class="img_footer">MonkeyUser.com</a>).
</figcaption>
</br>
<p>Predicting ad click-through rates and fraud detection are popular ML use cases because they directly impact business metrics. Higher click-through rates translate into increased ad revenue, while detecting and preventing fraudulent transactions saves money.</p>
<h2 id="data--feature-engineering">Data &amp; Feature Engineering<a hidden class="anchor" aria-hidden="true" href="#data--feature-engineering">#</a></h2>
<p>Let&rsquo;s look at how data can be handled in the data science perspective. For now, I will focus on sampling, labeling, and feature engineering techniques.</p>
<h3 id="data-sampling">Data Sampling<a hidden class="anchor" aria-hidden="true" href="#data-sampling">#</a></h3>
<p>To create train/validate/test sets, there are various data sampling techniques available. Two common approaches include <em>random sampling</em> and <em>stratified sampling</em>.</p>
<h3 id="data-labeling">Data Labeling<a hidden class="anchor" aria-hidden="true" href="#data-labeling">#</a></h3>
<p>When it comes to data labeling, there are several options to consider:</p>
<ul type="1">
  <li><strong>Hand-labeling:</strong> This approach can be expensive, time-consuming, and may raise concerns about data privacy.</li>
  <li><strong>Third-party service:</strong> Companies like Scale AI offer data labeling services and have recently secured significant contracts, such as the $250 million data labeling contract from the Department of Defense.</li>
  <li><strong>Benchmark datasets:</strong> Utilizing established benchmark datasets like ImageNet and BATADAL can provide pre-labeled data for specific tasks.</li>
  <li><strong>Methodological changes:</strong> If feasible, it's possible to switch from traditional supervised learning with training from scratch to alternative approaches like transfer learning, self-supervised learning, or semi-supervised learning. These methods can reduce the reliance on extensive labeled data.</li>
</ul>
<center>
    <img style="width: 50%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/training_dataset.png" />
</center>
<figcaption class="img_footer">
    Fig. 5. Finding a suitable dataset and processing it for specific task is crucial for intended application purposes.
    (Image source: 
    <a href="https://www.monkeyuser.com/2019/ai-training-datasets/" class="img_footer">MonkeyUser.com</a>).
</figcaption>
</br>
<h3 id="feature-engineering">Feature Engineering<a hidden class="anchor" aria-hidden="true" href="#feature-engineering">#</a></h3>
<p>The significance of feature engineering cannot be overstated in the development of ML models. Even with state-of-the-art ML architectures, performance can suffer if an inadequate set of features is used. While (deep learning) models can extract features to some extent, providing well-engineered features that enable the model to better comprehend the data can greatly benefit your application. By inputting carefully selected and curated features, you enhance the model&rsquo;s ability to effectively capture and utilize relevant information.</p>
<h2 id="ml-algorithms--evaluation">ML Algorithms &amp; Evaluation<a hidden class="anchor" aria-hidden="true" href="#ml-algorithms--evaluation">#</a></h2>
<p>Let&rsquo;s see what is Chip&rsquo;s tips in terms of suitable ML algorithm(s), training paradigm, and evaluation metrics.</p>
<h3 id="model-selection">Model Selection<a hidden class="anchor" aria-hidden="true" href="#model-selection">#</a></h3>
<p>Given the constraints of limited computation power and time, it is crucial to strategically choose ML models based on their advantages and disadvantages. This is where the knowledge gained from classes and academic papers becomes applicable. Benchmark datasets, such as ImageNet, SMAC, or VQA, can serve as valuable references for model selection. Additionally, factors like the number of parameters (model complexity) and interpretability can influence the choice of models. The availability of auto-selecting tools like <a href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html">AutoML</a> from H2O.ai or <a href="https://huggingface.co/autotrain">AutoTrain</a> from HuggingFace provides reasonable options as well.</p>
<h3 id="distributed-training-paradigms">Distributed Training Paradigms<a hidden class="anchor" aria-hidden="true" href="#distributed-training-paradigms">#</a></h3>
<p>Consideration of distributed training paradigms is important when dealing with large models or datasets. Let&rsquo;s examine <em>data parallelism</em> and <em>model parallelism</em>.</p>
<p><strong>Data parallelism</strong> involves splitting the data across multiple machines, training the model on each machine, and accumulating gradients.</p>
<p><strong>Model parallelism</strong>, on the other hand, involves training different components of the model on different machines. For instance, machine 0 handles the computation for the first two layers while machine 1 handles the next two layers. It&rsquo;s important to note that &ldquo;model parallelism&rdquo; can be misleading because in some cases, parallel execution doesn&rsquo;t occur across different parts of the model on different machines. Instead, each part is executed sequentially or consecutively.</p>
<center>
    <img style="width: 80%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/distributed_training.png" />
</center>
<figcaption class="img_footer">
    Fig. 6. Data parallelism vs. model parallelism.
    (Image source: 
    <a href="https://www.anyscale.com/blog/what-is-distributed-training" class="img_footer">anyscale.com</a>).
</figcaption>
</br>
<h3 id="model-evaluation">Model Evaluation<a hidden class="anchor" aria-hidden="true" href="#model-evaluation">#</a></h3>
<p>Deploying a model involves more than simply pickling the model and using it in a Python script. There are several important aspects to consider in the deployment process.</p>
<h2 id="model-deployment">Model Deployment<a hidden class="anchor" aria-hidden="true" href="#model-deployment">#</a></h2>
<p>Model deployment is not simply &ldquo;pickle&rdquo; the model and use it on a Python script, there are several aspects to be considered.</p>
<h3 id="batch-vs-online-training">Batch vs. Online Training<a hidden class="anchor" aria-hidden="true" href="#batch-vs-online-training">#</a></h3>
<p><strong>Online prediction</strong> is when predictions are generated and returned as soon as requests for these predictions arrive. For example, you enter an English sentence into Google Translate and get back its French translation immediately. When doing online prediction, requests are sent to the prediction service via RESTful APIs, that means to send back the input data, call model prediction and return the prediction result</p>
<p><strong>Batch prediction</strong> is when predictions are generated periodically or whenever triggered.  The predictions are stored somewhere, such as in SQL tables or an in-memory database, and retrieved as needed. For example, Netflix might generate movie recommendations for all of its users every four hours, and the precomputed recommendations are fetched and shown to users when they log on to Netflix. For example, every 4 hours, Netflix might generate movie recommendations for all of its users.</p>
<h3 id="model-compression">Model Compression<a hidden class="anchor" aria-hidden="true" href="#model-compression">#</a></h3>
<p>In scenarios where convolutional neural networks are used, model compression techniques can be applied. For example, replacing the convolutional layer with depth-wise separable convolutional layers can significantly reduce the number of parameters while maintaining performance. Similarly, classical ML algorithms like Decision Trees can be pruned to reduce model complexity.</p>
<h3 id="cloud-vs-hardware">Cloud vs. Hardware<a hidden class="anchor" aria-hidden="true" href="#cloud-vs-hardware">#</a></h3>
<p>Model deployment options include cloud deployment to platforms like AWS or GCP and hardware deployment, often referred to as edge computing. Cloud deployment offers scalability but comes with associated costs ranging from $50K to $2M per year. On the other hand, hardware deployment enables models to operate in environments with limited or unreliable internet connectivity, such as rural areas or developing countries. Edge computing also reduces network latency concerns. However, privacy risks still exist, as attackers could potentially steal user data by physically accessing the devices. Major companies like Google, Apple, and Tesla are actively developing their own chips optimized for edge computing.</p>
<center>
    <img style="width: 80%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/chips.png" />
</center>
<figcaption class="img_footer">
    Fig. 7. Google's Pixel 6 Tensor Chip, Apple's M1 Chip, Tesla's D1 Chip.
</figcaption>
</br>
<p>In support of the semiconductor industry, the <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2022/08/09/fact-sheet-chips-and-science-act-will-lower-costs-create-jobs-strengthen-supply-chains-and-counter-china/">CHIPS and Science Act</a> was signed by President Biden on August 9, 2022, aiming to strengthen the US semiconductor supply chain and foster research and development of advanced technologies within the country.</p>
<h2 id="infrastructure">Infrastructure<a hidden class="anchor" aria-hidden="true" href="#infrastructure">#</a></h2>
<p>The right infrastructure setup can automate processes, saving engineering time, accelerating ML application development and delivery, reducing the risk of bugs, and enabling new use cases. Conversely, a poorly implemented infrastructure can be cumbersome and costly to replace.</p>
<center>
    <img style="width: 90%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/tools.png" />
</center>
<figcaption class="img_footer">
    Fig. 8. ML layers of tools to build reliable infrastructure.
</figcaption>
</br>
<p><strong>Storage</strong>: <em>is where data is collected and stored</em>. It can range from simple setups like hard disk drives (HDD) or solid-state drives (SSD) to more sophisticated solutions like centralized storage in platforms such as Amazon S3 or Snowflake. Data can be stored in a single location or distributed across multiple locations.</p>
<p><strong>Resource Management</strong>: <em>comprises tools to schedule and orchestrate your workloads to make the most out of your available compute resources</em>. Popular examples in this category include Airflow, Kubeflow, and Metaflow, which help manage and allocate computing resources efficiently.</p>
<p><strong>ML Platform</strong>: <em>provides tools to aid the development of ML applications such as model stores, feature stores, and monitoring tools</em>. Prominent examples of ML platforms include SageMaker and MLflow, which provide comprehensive capabilities for ML application development and management.</p>
<p><strong>Deployment</strong>: Major cloud providers like AWS (SageMaker), GCP (Vertex AI), Azure (Azure ML), and Alibaba (Machine Learning) offer robust deployment options for ML applications. These platforms provide infrastructure and services to streamline the deployment process and ensure scalability and reliability.</p>
<p><strong>Development Environment</strong>: A variety of development environments are available to facilitate ML application development. Tools such as VS Code, PyCharm, Anaconda, Jupyter Notebook, Git, and Docker are commonly used by data scientists and developers to write and manage code, create reproducible environments, and collaborate efficiently.</p>
<h2 id="team-structures">Team Structures<a hidden class="anchor" aria-hidden="true" href="#team-structures">#</a></h2>
<p>In many job descriptions, it is common to see Data Scientists taking <em>ownership</em> of the entire process, from data collection to productionization. However, Netflix has implemented an effective team structure for full-stack data scientists.</p>
<p>Netflix&rsquo;s model involves specialists who initially own specific parts of a project. These specialists create tools and automation to streamline their respective areas. Data scientists can then leverage these tools to take ownership of their projects from end to end. As tools are developed and integrated with each other, the entire workflow is cohesive and well-integrated.</p>
<p>This team structure at Netflix allows for a seamless collaboration where specialists contribute their expertise to build tools, and data scientists can utilize these tools to manage the complete life cycle of their projects.</p>
<center>
    <img style="width: 100%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/netflix_team.png" />
</center>
<figcaption class="img_footer">
    Fig. 9. Netflix's full cycle data science development with specialists create reusable tools. (Image source: 
    <a href="https://netflixtechblog.com/full-cycle-developers-at-netflix-a08c31f83249" class="img_footer"> Netflix Technology Blog</a>).
</figcaption>
<h2 id="citation">Citation<a hidden class="anchor" aria-hidden="true" href="#citation">#</a></h2>
<p>Cited as:</p>
<blockquote>
    <summary>Nguyen, Minh. (May 2023). Designing Machine Learning Systems: A Summary.</summary>
    <summary>https://mnguyen0226.github.io/posts/ml_systems_design/post/.</summary>
</blockquote>
<p>Or</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">@article<span class="o">{</span>nguyen2023mlsys,
</span></span><span class="line"><span class="cl">  <span class="nv">title</span>   <span class="o">=</span> <span class="s2">&#34;Designing Machine Learning Systems: A Summary.&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">author</span>  <span class="o">=</span> <span class="s2">&#34;Nguyen, Minh&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">journal</span> <span class="o">=</span> <span class="s2">&#34;mnguyen0226.github.io&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">year</span>    <span class="o">=</span> <span class="s2">&#34;2023&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">month</span>   <span class="o">=</span> <span class="s2">&#34;May&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">url</span>     <span class="o">=</span> <span class="s2">&#34;https://mnguyen0226.github.io/posts/ml_systems_design/post/&#34;</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></div><h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<p>[1] “Full cycle developers at Netflix,” Medium, <a href="https://netflixtechblog.com/full-cycle-developers-at-netflix-a08c31f83249">https://netflixtechblog.com/full-cycle-developers-at-netflix-a08c31f83249</a> (accessed May 19, 2023).</p>
<p>[2] “President Biden Signs Chips and science act into law,” White &amp; Case LLP, <a href="https://www.whitecase.com/insight-alert/president-biden-signs-chips-and-science-act-law">https://www.whitecase.com/insight-alert/president-biden-signs-chips-and-science-act-law</a> (accessed May 19, 2023).</p>
<p>[3] “Cloud cost management and optimization by ANODOT,” Anodot, <a href="https://www.anodot.com/cloud-cost-management/">https://www.anodot.com/cloud-cost-management/</a> (accessed May 19, 2023).</p>
<p>[4] F. Chollet, “Xception: Deep learning with depthwise separable convolutions,” arXiv.org, <a href="https://arxiv.org/abs/1610.02357">https://arxiv.org/abs/1610.02357</a> (accessed May 19, 2023).</p>
<p>[5] C. Huyen, “Introduction to streaming for Data scientists,” Chip Huyen, <a href="https://huyenchip.com/2022/08/03/stream-processing-for-data-scientists.html#:~:text=Batch%20prediction%20means%20periodically%20generating,whenever%20they%20visit%20the%20website">https://huyenchip.com/2022/08/03/stream-processing-for-data-scientists.html#:~:text=Batch%20prediction%20means%20periodically%20generating,whenever%20they%20visit%20the%20website</a>. (accessed May 19, 2023).</p>
<p>[6] Y. Wu et al., “Google’s Neural Machine Translation System: Bridging the gap between human and machine translation,” arXiv.org, <a href="https://arxiv.org/abs/1609.08144">https://arxiv.org/abs/1609.08144</a> (accessed May 19, 2023).</p>
<p>[7] “What is distributed training?,” Anyscale, <a href="https://www.anyscale.com/blog/what-is-distributed-training">https://www.anyscale.com/blog/what-is-distributed-training</a> (accessed May 19, 2023).</p>
<p>[8] VQA: Visual question answering | IEEE conference publication - IEEE xplore, <a href="https://ieeexplore.ieee.org/document/7410636">https://ieeexplore.ieee.org/document/7410636</a> (accessed May 19, 2023).</p>
<p>[9] B. Ellis et al., “SMACv2: An improved benchmark for cooperative multi-agent reinforcement learning,” arXiv.org, <a href="https://arxiv.org/abs/2212.07489">https://arxiv.org/abs/2212.07489</a> (accessed May 19, 2023).</p>
<p>[10] Practical lessons from predicting clicks on ads at facebook, <a href="https://quinonero.net/Publications/predicting-clicks-facebook.pdf">https://quinonero.net/Publications/predicting-clicks-facebook.pdf</a> (accessed May 19, 2023).</p>
<p>[11] “Scale AI selected by U.S. Department of Defense to accelerate government’s AI capabilities,” Business Wire, <a href="https://www.businesswire.com/news/home/20220131005304/en/Scale-AI-Selected-by-U.S.-Department-of-Defense-to-Accelerate-Government%E2%80%99s-AI-Capabilities">https://www.businesswire.com/news/home/20220131005304/en/Scale-AI-Selected-by-U.S.-Department-of-Defense-to-Accelerate-Government%E2%80%99s-AI-Capabilities</a> (accessed May 19, 2023).</p>
<p>[12] “Deep learning with python,” Manning Publications, <a href="https://www.manning.com/books/deep-learning-with-python">https://www.manning.com/books/deep-learning-with-python</a> (accessed May 19, 2023).</p>
<p>[13] J. Henriksen, “Valuing lyft requires a deep look into unit economics,” Forbes, <a href="https://www.forbes.com/sites/jeffhenriksen/2019/05/17/valuing-lyft-requires-a-deep-look-into-unit-economics/?sh=17155c9a7add">https://www.forbes.com/sites/jeffhenriksen/2019/05/17/valuing-lyft-requires-a-deep-look-into-unit-economics/?sh=17155c9a7add</a> (accessed May 19, 2023).</p>
<p>[14] L. Ceci and J. 7, “Mobile app user acquisition cost 2019,” Statista, <a href="https://www.statista.com/statistics/185736/mobile-app-average-user-acquisition-cost/">https://www.statista.com/statistics/185736/mobile-app-average-user-acquisition-cost/</a> (accessed May 19, 2023).</p>
<p>[15] C. Huyen, “Designing machine learning systems,” O’Reilly Online Learning, <a href="https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/">https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/</a> (accessed May 19, 2023).</p>
<center>
    <img class="img_size" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/ml_systems_design/imgs/mcafee.jpg" />
</center>
<figcaption class="img_footer">
    Fig. 10. Morning hike at McAfee Knob, Roanoke, Virginia, U.S.A.
</figcaption>
<!-- CSS Styling -->
<style>
.img_size {
  width: 100%;
}

.img_footer {
    color: #888888;
    text-align: center;
}
</style><blockquote>
</blockquote>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://mnguyen0226.github.io/tags/paper-reading/">paper-reading</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://mnguyen0226.github.io/posts/solid_principles/post/">
    <span class="title">Next »</span>
    <br>
    <span>S.O.L.I.D Principles Explained</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Designing Machine Learning Systems: A Summary on twitter"
        href="https://twitter.com/intent/tweet/?text=Designing%20Machine%20Learning%20Systems%3a%20A%20Summary&amp;url=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fml_systems_design%2fpost%2f&amp;hashtags=paper-reading">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Designing Machine Learning Systems: A Summary on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fml_systems_design%2fpost%2f&amp;title=Designing%20Machine%20Learning%20Systems%3a%20A%20Summary&amp;summary=Designing%20Machine%20Learning%20Systems%3a%20A%20Summary&amp;source=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fml_systems_design%2fpost%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Designing Machine Learning Systems: A Summary on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fml_systems_design%2fpost%2f&title=Designing%20Machine%20Learning%20Systems%3a%20A%20Summary">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Designing Machine Learning Systems: A Summary on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fml_systems_design%2fpost%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Designing Machine Learning Systems: A Summary on whatsapp"
        href="https://api.whatsapp.com/send?text=Designing%20Machine%20Learning%20Systems%3a%20A%20Summary%20-%20https%3a%2f%2fmnguyen0226.github.io%2fposts%2fml_systems_design%2fpost%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Designing Machine Learning Systems: A Summary on telegram"
        href="https://telegram.me/share/url?text=Designing%20Machine%20Learning%20Systems%3a%20A%20Summary&amp;url=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fml_systems_design%2fpost%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://mnguyen0226.github.io/">Minh T. Nguyen</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>

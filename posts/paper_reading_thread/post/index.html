<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Paper-Reading Thread | Minh T. Nguyen</title>
<meta name="keywords" content="paper-reading, long-read">
<meta name="description" content="Notes on (1) papers I read.">
<meta name="author" content="Minh T. Nguyen">
<link rel="canonical" href="https://mnguyen0226.github.io/posts/paper_reading_thread/post/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css" integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe&#43;FVUFzPh7U=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<link rel="apple-touch-icon" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<link rel="mask-icon" href="https://mnguyen0226.github.io/favicon/android-chrome-192x192.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Paper-Reading Thread" />
<meta property="og:description" content="Notes on (1) papers I read." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mnguyen0226.github.io/posts/paper_reading_thread/post/" /><meta property="og:image" content="https://mnguyen0226.github.io/papermod-cover.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-18T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-05-18T00:00:00+00:00" />
<meta property="og:see_also" content="https://mnguyen0226.github.io/posts/ml_systems_design/post/" /><meta property="og:see_also" content="https://mnguyen0226.github.io/posts/multitask_learning/post/" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://mnguyen0226.github.io/papermod-cover.png"/>

<meta name="twitter:title" content="Paper-Reading Thread"/>
<meta name="twitter:description" content="Notes on (1) papers I read."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://mnguyen0226.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Paper-Reading Thread",
      "item": "https://mnguyen0226.github.io/posts/paper_reading_thread/post/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Paper-Reading Thread",
  "name": "Paper-Reading Thread",
  "description": "Notes on (1) papers I read.",
  "keywords": [
    "paper-reading", "long-read"
  ],
  "articleBody": "Status: [Latest]\nIn the field of machine learning (ML), staying ahead of the curve involves actively reading papers. Renowned ML researcher Andrew Ng, from Stanford University and founder of Coursera and Landing.AI, provides valuable tips and tricks in his lecture for understanding ML domains and effectively reading research papers. According to Ng, reading 50-100 papers is crucial for gaining a deep understanding of the field.\nHow to select papers? To select papers, start by compiling a list that includes research papers, Medium posts, blog posts, GitHub repositories, and conference materials. From this list, choose five papers that you find most intriguing or relevant, and mark your initial understanding percentage while reading them. If a paper has been discredited by other researchers, it’s advisable to discard it. Otherwise, reread and strive to fully comprehend it. Continuously add more papers to your reading list to expand your knowledge and understanding of the field.\nHow to read one paper? It’s recommended to avoid reading it from start to finish in a single pass. Instead, employ a spaced-repetition approach and read the paper in multiple passes. Here’s a suggested approach:\n1st pass: Focus on the title, abstract, and figures, while skimming through the rest of the paper. 2nd pass: Concentrate on the introduction, conclusion, key figures, and skim the remaining sections. 3rd pass: Revisit the entire paper, skipping parts that you already understand well. 4th pass: Dive into the mathematical details and equations, understanding them thoroughly. The total time spent on these four passes may vary from 30 minutes to 2 hours, depending on the complexity and length of the paper. After going through the four reading passes, try to answer the following questions:\nQ1: What were the authors aiming to accomplish with their research? Q2: What were the key elements or approaches used in their work? Q3: What aspects of their research can you utilize or apply in your own work? Q4: Which additional references or sources would you like to explore to deepen your understanding of the topic? Fig. 1. Types of scientific paper (Image source: xkcd.com). Why do I start this paper-reading-and-noting journey? Embarking on a journey of reading and taking notes on research papers holds significant value for me. Throughout my undergraduate and graduate studies, I had the privilege of working at a research lab, which provided me with invaluable opportunities to delve into various papers and present my insights in academic forums. Recognizing the potential benefits of open-source note sharing, I aim to contribute to the machine learning community by documenting my findings. As the saying goes, teaching is a powerful way to enhance our own learning. In line with this notion, Eugene Yan emphasizes the importance of paper reading: it broadens our perspective, keeps us up to date, and enhances our efficiency by reducing time and effort.\nThe following collection of topics and papers draws from the Applied Deep Learning Github repository, serving as a foundation for expanding my repertoire of knowledge. Over time, I will continually augment this list by incorporating additional noteworthy papers.\nImage Classification Large Networks D. Cireşan et al. Multi-column Deep Neural Networks for Image Classification (2012). ▪ Q1: ▪ Q2: ▪ Q3: ▪ Q4: ▪ Additional Resources: Small Networks AutoML Robustness Visualizing \u0026 Understanding Transfer Learning Image Transformation Semantic Segmentation Super-Resolution, Denoising, and Colorization Pose Estimation Optical Flow and Depth Estimation Object Detection Two Stage Detectors One Stage Detectors Face Recognitionn \u0026 Detection Video 3D NLP Word Representations Text Classification Neural Machine Translation Language Modeling Multimodal Learning Generative Networks Variational Auto-Encoders Unconditional GANs Conditional GANs Diffusion Models Advanced Topics Domain Adaptation Few Shot Learning Federated Learning Semi-Supervised Learning Speed \u0026 Music Recognition Synthesis Modeling Reinforcement Learning Games Simulated Environments Real Environments Uncertainty Quantification \u0026 Multitask Learning Graph Neural Networks Recommender Systems Computational Biology Citation Cited as:\nNguyen, Minh. (May 2023). Paper-Reading Thread. https://mnguyen0226.github.io/posts/paper_reading_thread/post/. Or\n@article{nguyen2023paper, title = \"Paper-Reading Thread.\", author = \"Nguyen, Minh\", journal = \"mnguyen0226.github.io\", year = \"2023\", month = \"May\", url = \"https://mnguyen0226.github.io/posts/paper_reading_thread/post/\" } References [1] “Stanford CS230: Deep Learning | autumn 2018 | lecture 8 - career advice / reading research papers,” YouTube, https://www.youtube.com/watch?v=733m6qBH-jI\u0026amp;ab_channel=StanfordOnline (accessed May 19, 2023).\n[2] Maziarraissi, “Maziarraissi/applied-deep-learning: Applied deep learning course,” GitHub, https://github.com/maziarraissi/Applied-Deep-Learning (accessed May 19, 2023).\n[3] D. Cireşan, U. Meier, and J. Schmidhuber, “Multi-column deep neural networks for Image Classification,” arXiv.org, https://arxiv.org/abs/1202.2745 (accessed May 19, 2023).\n[4] E. Yan, “How reading papers helps you be a more effective data scientist,” eugeneyan.com, https://eugeneyan.com/writing/why-read-papers/ (accessed May 19, 2023).\nFig. 2. Coffee next to train-track at Hanoi, Vietnam. (Image source: Dave Weatherall @ Unsplash) ",
  "wordCount" : "757",
  "inLanguage": "en",
  "datePublished": "2023-05-18T00:00:00Z",
  "dateModified": "2023-05-18T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Minh T. Nguyen"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://mnguyen0226.github.io/posts/paper_reading_thread/post/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Minh T. Nguyen",
    "logo": {
      "@type": "ImageObject",
      "url": "https://mnguyen0226.github.io/favicon/android-chrome-192x192.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://mnguyen0226.github.io/" accesskey="h" title="Minh T. Nguyen (Alt + H)">Minh T. Nguyen</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://mnguyen0226.github.io/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://mnguyen0226.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://mnguyen0226.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://mnguyen0226.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      Paper-Reading Thread
    </h1>
    <div class="post-description">
      Notes on (1) papers I read.
    </div>
    <div class="post-meta"><span title='2023-05-18 00:00:00 +0000 UTC'>May 18, 2023</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Minh T. Nguyen

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#image-classification" aria-label="Image Classification">Image Classification</a><ul>
                        
                <li>
                    <a href="#large-networks" aria-label="Large Networks">Large Networks</a></li>
                <li>
                    <a href="#small-networks" aria-label="Small Networks">Small Networks</a></li>
                <li>
                    <a href="#automl" aria-label="AutoML">AutoML</a></li>
                <li>
                    <a href="#robustness" aria-label="Robustness">Robustness</a></li>
                <li>
                    <a href="#visualizing--understanding" aria-label="Visualizing &amp;amp; Understanding">Visualizing &amp; Understanding</a></li>
                <li>
                    <a href="#transfer-learning" aria-label="Transfer Learning">Transfer Learning</a></li></ul>
                </li>
                <li>
                    <a href="#image-transformation" aria-label="Image Transformation">Image Transformation</a><ul>
                        
                <li>
                    <a href="#semantic-segmentation" aria-label="Semantic Segmentation">Semantic Segmentation</a></li>
                <li>
                    <a href="#super-resolution-denoising-and-colorization" aria-label="Super-Resolution, Denoising, and Colorization">Super-Resolution, Denoising, and Colorization</a></li>
                <li>
                    <a href="#pose-estimation" aria-label="Pose Estimation">Pose Estimation</a></li>
                <li>
                    <a href="#optical-flow-and-depth-estimation" aria-label="Optical Flow and Depth Estimation">Optical Flow and Depth Estimation</a></li></ul>
                </li>
                <li>
                    <a href="#object-detection" aria-label="Object Detection">Object Detection</a><ul>
                        
                <li>
                    <a href="#two-stage-detectors" aria-label="Two Stage Detectors">Two Stage Detectors</a></li>
                <li>
                    <a href="#one-stage-detectors" aria-label="One Stage Detectors">One Stage Detectors</a></li></ul>
                </li>
                <li>
                    <a href="#face-recognitionn--detection" aria-label="Face Recognitionn &amp;amp; Detection">Face Recognitionn &amp; Detection</a></li>
                <li>
                    <a href="#video" aria-label="Video">Video</a></li>
                <li>
                    <a href="#3d" aria-label="3D">3D</a></li>
                <li>
                    <a href="#nlp" aria-label="NLP">NLP</a><ul>
                        
                <li>
                    <a href="#word-representations" aria-label="Word Representations">Word Representations</a></li>
                <li>
                    <a href="#text-classification" aria-label="Text Classification">Text Classification</a></li>
                <li>
                    <a href="#neural-machine-translation" aria-label="Neural Machine Translation">Neural Machine Translation</a></li>
                <li>
                    <a href="#language-modeling" aria-label="Language Modeling">Language Modeling</a></li></ul>
                </li>
                <li>
                    <a href="#multimodal-learning" aria-label="Multimodal Learning">Multimodal Learning</a></li>
                <li>
                    <a href="#generative-networks" aria-label="Generative Networks">Generative Networks</a><ul>
                        
                <li>
                    <a href="#variational-auto-encoders" aria-label="Variational Auto-Encoders">Variational Auto-Encoders</a></li>
                <li>
                    <a href="#unconditional-gans" aria-label="Unconditional GANs">Unconditional GANs</a></li>
                <li>
                    <a href="#conditional-gans" aria-label="Conditional GANs">Conditional GANs</a></li>
                <li>
                    <a href="#diffusion-models" aria-label="Diffusion Models">Diffusion Models</a></li></ul>
                </li>
                <li>
                    <a href="#advanced-topics" aria-label="Advanced Topics">Advanced Topics</a><ul>
                        
                <li>
                    <a href="#domain-adaptation" aria-label="Domain Adaptation">Domain Adaptation</a></li>
                <li>
                    <a href="#few-shot-learning" aria-label="Few Shot Learning">Few Shot Learning</a></li>
                <li>
                    <a href="#federated-learning" aria-label="Federated Learning">Federated Learning</a></li>
                <li>
                    <a href="#semi-supervised-learning" aria-label="Semi-Supervised Learning">Semi-Supervised Learning</a></li></ul>
                </li>
                <li>
                    <a href="#speed--music" aria-label="Speed &amp;amp; Music">Speed &amp; Music</a><ul>
                        
                <li>
                    <a href="#recognition" aria-label="Recognition">Recognition</a></li>
                <li>
                    <a href="#synthesis" aria-label="Synthesis">Synthesis</a></li>
                <li>
                    <a href="#modeling" aria-label="Modeling">Modeling</a></li></ul>
                </li>
                <li>
                    <a href="#reinforcement-learning" aria-label="Reinforcement Learning">Reinforcement Learning</a><ul>
                        
                <li>
                    <a href="#games" aria-label="Games">Games</a></li>
                <li>
                    <a href="#simulated-environments" aria-label="Simulated Environments">Simulated Environments</a></li>
                <li>
                    <a href="#real-environments" aria-label="Real Environments">Real Environments</a></li>
                <li>
                    <a href="#uncertainty-quantification--multitask-learning" aria-label="Uncertainty Quantification &amp;amp; Multitask Learning">Uncertainty Quantification &amp; Multitask Learning</a></li></ul>
                </li>
                <li>
                    <a href="#graph-neural-networks" aria-label="Graph Neural Networks">Graph Neural Networks</a></li>
                <li>
                    <a href="#recommender-systems" aria-label="Recommender Systems">Recommender Systems</a></li>
                <li>
                    <a href="#computational-biology" aria-label="Computational Biology">Computational Biology</a></li>
                <li>
                    <a href="#citation" aria-label="Citation">Citation</a></li>
                <li>
                    <a href="#references" aria-label="References">References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p style="color: #286EE0"><strong>Status:</strong> [Latest]</p>
<p>In the field of machine learning (ML), staying ahead of the curve involves actively reading papers. Renowned ML researcher Andrew Ng, from Stanford University and founder of Coursera and Landing.AI, provides valuable tips and tricks in his <a href="https://www.youtube.com/watch?v=733m6qBH-jI&amp;ab_channel=StanfordOnline">lecture</a> for understanding ML domains and effectively reading research papers. According to Ng, reading 50-100 papers is crucial for gaining a deep understanding of the field.</p>
<p><strong>How to select papers?</strong> To select papers, start by compiling a list that includes research papers, Medium posts, blog posts, GitHub repositories, and conference materials. From this list, choose five papers that you find most intriguing or relevant, and mark your initial understanding percentage while reading them. If a paper has been discredited by other researchers, it&rsquo;s advisable to discard it. Otherwise, reread and strive to fully comprehend it. Continuously add more papers to your reading list to expand your knowledge and understanding of the field.</p>
<p><strong>How to read one paper?</strong> It&rsquo;s recommended to avoid reading it from start to finish in a single pass. Instead, employ a spaced-repetition approach and read the paper in multiple passes. Here&rsquo;s a suggested approach:</p>
<ul type="1">
    <li><strong>1st pass</strong>: Focus on the title, abstract, and figures, while skimming through the rest of the paper.</li>
    <li><strong>2nd pass</strong>: Concentrate on the introduction, conclusion, key figures, and skim the remaining sections.</li>
    <li><strong>3rd pass</strong>: Revisit the entire paper, skipping parts that you already understand well.</li>
    <li><strong>4th pass</strong>: Dive into the mathematical details and equations, understanding them thoroughly.</li>
</ul>
<p>The total time spent on these four passes may vary from 30 minutes to 2 hours, depending on the complexity and length of the paper. After going through the four reading passes, try to answer the following questions:</p>
<ul type="1">
    <li><strong>Q1</strong>: What were the authors aiming to accomplish with their research?</li>
    <li><strong>Q2</strong>: What were the key elements or approaches used in their work?</li>
    <li><strong>Q3</strong>: What aspects of their research can you utilize or apply in your own work?</li>
    <li><strong>Q4</strong>: Which additional references or sources would you like to explore to deepen your understanding of the topic?</li>
</ul>
<center>
    <img style="width: 70%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/paper_reading_thread/imgs/types_of_scientific_paper.png" />
</center>
<figcaption class="img_footer">
    Fig. 1. Types of scientific paper (Image source: 
    <a href="https://xkcd.com/2456/" class="img_footer">xkcd.com</a>).
</figcaption>
</br>
<p><strong>Why do I start this paper-reading-and-noting journey?</strong>
Embarking on a journey of reading and taking notes on research papers holds significant value for me. Throughout my undergraduate and graduate studies, I had the privilege of working at a research lab, which provided me with invaluable opportunities to delve into various papers and present my insights in academic forums. Recognizing the potential benefits of open-source note sharing, I aim to contribute to the machine learning community by documenting my findings. As the saying goes, teaching is a powerful way to enhance our own learning. In line with this notion, <a href="https://twitter.com/eugeneyan/status/1300954984461156352?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1300954984461156352%7Ctwgr%5Eb55e848832d840c4d87e38f0f075ad552b653cef%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Feugeneyan.com%2Fwriting%2Fwhy-read-papers%2F">Eugene Yan</a> emphasizes the importance of paper reading: it broadens our perspective, keeps us up to date, and enhances our efficiency by reducing time and effort.</p>
<p>The following collection of topics and papers draws from the <a href="https://github.com/maziarraissi/Applied-Deep-Learning">Applied Deep Learning</a> Github repository, serving as a foundation for expanding my repertoire of knowledge. Over time, I will continually augment this list by incorporating additional noteworthy papers.</p>
<h2 id="image-classification">Image Classification<a hidden class="anchor" aria-hidden="true" href="#image-classification">#</a></h2>
<h3 id="large-networks">Large Networks<a hidden class="anchor" aria-hidden="true" href="#large-networks">#</a></h3>
<details>
    <summary>
        <strong>D. Cireşan et al.</strong>
        <a href="Multi-column Deep Neural Networks for Image Classification"> Multi-column Deep Neural Networks for Image Classification</a> (2012).
    </summary>
    <blockquote>
            <summary>
                <img src="https://geps.dev/progress/70">
            </summary>
            <summary>
                ▪ Q1:
            </summary>
            <summary>
                ▪ Q2:
            </summary>
            <summary>
                ▪ Q3:
            </summary>
            <summary>
                ▪ Q4:
            </summary>
            <summary>
                ▪ Additional Resources:
            </summary>
    </blockquote>
</details>
<h3 id="small-networks">Small Networks<a hidden class="anchor" aria-hidden="true" href="#small-networks">#</a></h3>
<h3 id="automl">AutoML<a hidden class="anchor" aria-hidden="true" href="#automl">#</a></h3>
<h3 id="robustness">Robustness<a hidden class="anchor" aria-hidden="true" href="#robustness">#</a></h3>
<h3 id="visualizing--understanding">Visualizing &amp; Understanding<a hidden class="anchor" aria-hidden="true" href="#visualizing--understanding">#</a></h3>
<h3 id="transfer-learning">Transfer Learning<a hidden class="anchor" aria-hidden="true" href="#transfer-learning">#</a></h3>
<hr>
<h2 id="image-transformation">Image Transformation<a hidden class="anchor" aria-hidden="true" href="#image-transformation">#</a></h2>
<h3 id="semantic-segmentation">Semantic Segmentation<a hidden class="anchor" aria-hidden="true" href="#semantic-segmentation">#</a></h3>
<h3 id="super-resolution-denoising-and-colorization">Super-Resolution, Denoising, and Colorization<a hidden class="anchor" aria-hidden="true" href="#super-resolution-denoising-and-colorization">#</a></h3>
<h3 id="pose-estimation">Pose Estimation<a hidden class="anchor" aria-hidden="true" href="#pose-estimation">#</a></h3>
<h3 id="optical-flow-and-depth-estimation">Optical Flow and Depth Estimation<a hidden class="anchor" aria-hidden="true" href="#optical-flow-and-depth-estimation">#</a></h3>
<hr>
<h2 id="object-detection">Object Detection<a hidden class="anchor" aria-hidden="true" href="#object-detection">#</a></h2>
<h3 id="two-stage-detectors">Two Stage Detectors<a hidden class="anchor" aria-hidden="true" href="#two-stage-detectors">#</a></h3>
<h3 id="one-stage-detectors">One Stage Detectors<a hidden class="anchor" aria-hidden="true" href="#one-stage-detectors">#</a></h3>
<hr>
<h2 id="face-recognitionn--detection">Face Recognitionn &amp; Detection<a hidden class="anchor" aria-hidden="true" href="#face-recognitionn--detection">#</a></h2>
<hr>
<h2 id="video">Video<a hidden class="anchor" aria-hidden="true" href="#video">#</a></h2>
<hr>
<h2 id="3d">3D<a hidden class="anchor" aria-hidden="true" href="#3d">#</a></h2>
<hr>
<h2 id="nlp">NLP<a hidden class="anchor" aria-hidden="true" href="#nlp">#</a></h2>
<h3 id="word-representations">Word Representations<a hidden class="anchor" aria-hidden="true" href="#word-representations">#</a></h3>
<h3 id="text-classification">Text Classification<a hidden class="anchor" aria-hidden="true" href="#text-classification">#</a></h3>
<h3 id="neural-machine-translation">Neural Machine Translation<a hidden class="anchor" aria-hidden="true" href="#neural-machine-translation">#</a></h3>
<h3 id="language-modeling">Language Modeling<a hidden class="anchor" aria-hidden="true" href="#language-modeling">#</a></h3>
<hr>
<h2 id="multimodal-learning">Multimodal Learning<a hidden class="anchor" aria-hidden="true" href="#multimodal-learning">#</a></h2>
<hr>
<h2 id="generative-networks">Generative Networks<a hidden class="anchor" aria-hidden="true" href="#generative-networks">#</a></h2>
<h3 id="variational-auto-encoders">Variational Auto-Encoders<a hidden class="anchor" aria-hidden="true" href="#variational-auto-encoders">#</a></h3>
<h3 id="unconditional-gans">Unconditional GANs<a hidden class="anchor" aria-hidden="true" href="#unconditional-gans">#</a></h3>
<h3 id="conditional-gans">Conditional GANs<a hidden class="anchor" aria-hidden="true" href="#conditional-gans">#</a></h3>
<h3 id="diffusion-models">Diffusion Models<a hidden class="anchor" aria-hidden="true" href="#diffusion-models">#</a></h3>
<hr>
<h2 id="advanced-topics">Advanced Topics<a hidden class="anchor" aria-hidden="true" href="#advanced-topics">#</a></h2>
<h3 id="domain-adaptation">Domain Adaptation<a hidden class="anchor" aria-hidden="true" href="#domain-adaptation">#</a></h3>
<h3 id="few-shot-learning">Few Shot Learning<a hidden class="anchor" aria-hidden="true" href="#few-shot-learning">#</a></h3>
<h3 id="federated-learning">Federated Learning<a hidden class="anchor" aria-hidden="true" href="#federated-learning">#</a></h3>
<h3 id="semi-supervised-learning">Semi-Supervised Learning<a hidden class="anchor" aria-hidden="true" href="#semi-supervised-learning">#</a></h3>
<hr>
<h2 id="speed--music">Speed &amp; Music<a hidden class="anchor" aria-hidden="true" href="#speed--music">#</a></h2>
<h3 id="recognition">Recognition<a hidden class="anchor" aria-hidden="true" href="#recognition">#</a></h3>
<h3 id="synthesis">Synthesis<a hidden class="anchor" aria-hidden="true" href="#synthesis">#</a></h3>
<h3 id="modeling">Modeling<a hidden class="anchor" aria-hidden="true" href="#modeling">#</a></h3>
<hr>
<h2 id="reinforcement-learning">Reinforcement Learning<a hidden class="anchor" aria-hidden="true" href="#reinforcement-learning">#</a></h2>
<h3 id="games">Games<a hidden class="anchor" aria-hidden="true" href="#games">#</a></h3>
<h3 id="simulated-environments">Simulated Environments<a hidden class="anchor" aria-hidden="true" href="#simulated-environments">#</a></h3>
<h3 id="real-environments">Real Environments<a hidden class="anchor" aria-hidden="true" href="#real-environments">#</a></h3>
<h3 id="uncertainty-quantification--multitask-learning">Uncertainty Quantification &amp; Multitask Learning<a hidden class="anchor" aria-hidden="true" href="#uncertainty-quantification--multitask-learning">#</a></h3>
<hr>
<h2 id="graph-neural-networks">Graph Neural Networks<a hidden class="anchor" aria-hidden="true" href="#graph-neural-networks">#</a></h2>
<hr>
<h2 id="recommender-systems">Recommender Systems<a hidden class="anchor" aria-hidden="true" href="#recommender-systems">#</a></h2>
<hr>
<h2 id="computational-biology">Computational Biology<a hidden class="anchor" aria-hidden="true" href="#computational-biology">#</a></h2>
<h2 id="citation">Citation<a hidden class="anchor" aria-hidden="true" href="#citation">#</a></h2>
<p>Cited as:</p>
<blockquote>
    <summary>Nguyen, Minh. (May 2023). Paper-Reading Thread.</summary>
    <summary>https://mnguyen0226.github.io/posts/paper_reading_thread/post/.</summary>
</blockquote>
<p>Or</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">@article<span class="o">{</span>nguyen2023paper,
</span></span><span class="line"><span class="cl">  <span class="nv">title</span>   <span class="o">=</span> <span class="s2">&#34;Paper-Reading Thread.&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">author</span>  <span class="o">=</span> <span class="s2">&#34;Nguyen, Minh&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">journal</span> <span class="o">=</span> <span class="s2">&#34;mnguyen0226.github.io&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">year</span>    <span class="o">=</span> <span class="s2">&#34;2023&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">month</span>   <span class="o">=</span> <span class="s2">&#34;May&#34;</span>,
</span></span><span class="line"><span class="cl">  <span class="nv">url</span>     <span class="o">=</span> <span class="s2">&#34;https://mnguyen0226.github.io/posts/paper_reading_thread/post/&#34;</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></div><h2 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h2>
<p>[1] “Stanford CS230: Deep Learning | autumn 2018 | lecture 8 - career advice / reading research papers,” YouTube, <a href="https://www.youtube.com/watch?v=733m6qBH-jI&amp;amp;ab_channel=StanfordOnline">https://www.youtube.com/watch?v=733m6qBH-jI&amp;amp;ab_channel=StanfordOnline</a> (accessed May 19, 2023).</p>
<p>[2] Maziarraissi, “Maziarraissi/applied-deep-learning: Applied deep learning course,” GitHub, <a href="https://github.com/maziarraissi/Applied-Deep-Learning">https://github.com/maziarraissi/Applied-Deep-Learning</a> (accessed May 19, 2023).</p>
<p>[3] D. Cireşan, U. Meier, and J. Schmidhuber, “Multi-column deep neural networks for Image Classification,” arXiv.org, <a href="https://arxiv.org/abs/1202.2745">https://arxiv.org/abs/1202.2745</a> (accessed May 19, 2023).</p>
<p>[4] E. Yan, “How reading papers helps you be a more effective data scientist,” eugeneyan.com, <a href="https://eugeneyan.com/writing/why-read-papers/">https://eugeneyan.com/writing/why-read-papers/</a> (accessed May 19, 2023).</p>
<center>
    <img style="width: 80%" src="https://raw.githubusercontent.com/mnguyen0226/mnguyen0226.github.io/main/content/posts/paper_reading_thread/imgs/hanoi.png" />
</center>
<figcaption class="img_footer">
    Fig. 2. Coffee next to train-track at Hanoi, Vietnam. </br>
    (Image source: 
    <a href="https://unsplash.com/photos/u-z8Cq8EZgM" class="img_footer">Dave Weatherall @ Unsplash</a>)
</figcaption>
<!-- CSS Styling -->
<style>
.img_size {
  width: 100%;
}

.img_footer {
    color: #888888;
    text-align: center;
}
</style><blockquote>
</blockquote>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://mnguyen0226.github.io/tags/paper-reading/">paper-reading</a></li>
      <li><a href="https://mnguyen0226.github.io/tags/long-read/">long-read</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://mnguyen0226.github.io/posts/ml_systems_design/post/">
    <span class="title">Next »</span>
    <br>
    <span>Designing Machine Learning Systems: A Summary</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper-Reading Thread on twitter"
        href="https://twitter.com/intent/tweet/?text=Paper-Reading%20Thread&amp;url=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fpaper_reading_thread%2fpost%2f&amp;hashtags=paper-reading%2clong-read">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper-Reading Thread on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fpaper_reading_thread%2fpost%2f&amp;title=Paper-Reading%20Thread&amp;summary=Paper-Reading%20Thread&amp;source=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fpaper_reading_thread%2fpost%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper-Reading Thread on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fpaper_reading_thread%2fpost%2f&title=Paper-Reading%20Thread">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper-Reading Thread on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fpaper_reading_thread%2fpost%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper-Reading Thread on whatsapp"
        href="https://api.whatsapp.com/send?text=Paper-Reading%20Thread%20-%20https%3a%2f%2fmnguyen0226.github.io%2fposts%2fpaper_reading_thread%2fpost%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Paper-Reading Thread on telegram"
        href="https://telegram.me/share/url?text=Paper-Reading%20Thread&amp;url=https%3a%2f%2fmnguyen0226.github.io%2fposts%2fpaper_reading_thread%2fpost%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://mnguyen0226.github.io/">Minh T. Nguyen</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
